{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15022c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "\n",
    "from pandas.io.pytables import performance_doc\n",
    "\n",
    "class MyClassifier_25:  \n",
    "\n",
    "    def __init__(self,dataset,class1:int,class2:int) -> None:\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.classes = {1 : class1, -1: class2, 0:None}\n",
    "        self.dataset_train = dataset\n",
    "\n",
    "        #data prep\n",
    "        self.trainlabel,self.traindata = self.prepare_binary(self.dataset_train)\n",
    "        \n",
    "        #train the classfier \n",
    "        self.train(self.traindata,self.trainlabel)\n",
    "\n",
    "        \n",
    "    \n",
    "    def prepare_binary(self,dataset):\n",
    "\n",
    "        #USAGE    \n",
    "        # Since we have to deal with a binary classifier to diffrentiate between digits 7 and 1, \n",
    "        # we choose only those examples.\n",
    "        # If asked to train a classifier on any other pair a, b (say),\n",
    "        # please pass the right arguments to the following function as follows:\n",
    "        # trainlabel, traindata, dataTargetDf = prepare_binary(a,b)\n",
    "\n",
    "\n",
    "        # We now assign +1 to one class and -1 to the other;\n",
    "        # Therefore +1 and -1 will be the new labels\n",
    "        class1 = self.classes[1]\n",
    "        class2 = self.classes[-1]\n",
    "\n",
    "        trainlabel = dataset.loc[(dataset['label']== class1)  | (dataset['label']== class2) ]['label']\n",
    "        trainlabel.loc[trainlabel == class1] = 1\n",
    "        trainlabel.loc[trainlabel == class2] = -1\n",
    "        trainlabel = trainlabel.to_numpy()\n",
    "    \n",
    "        #In order to match dimensions of \"traindata\" and \"trainlabel\", we convert trainlabel to two dimension array\n",
    "        # for hinge loss\n",
    "        trainlabel= np.reshape(trainlabel, (trainlabel.shape[0],1))   \n",
    "\n",
    "        # We now extract the features for the two classes\n",
    "        traindata = dataset.loc[(dataset['label']== class1)  | (dataset['label']== class2) ]\n",
    "        traindata = traindata.drop(labels = [\"label\"],axis = 1).to_numpy()\n",
    "\n",
    "        # print(traindata.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        return trainlabel, traindata\n",
    "\n",
    "    def target_df(self,traindata,trainlabel):\n",
    "        # Also creating a dataframe with these, so that we can randomize the order of the train data when needed without\n",
    "        # losing the mapping between feature vectors and the target labels\n",
    "        trainDf=pd.DataFrame(traindata)\n",
    "        targetDf=pd.DataFrame(trainlabel,columns=['target'])\n",
    "        \n",
    "        dataTargetDf = pd.concat([trainDf, targetDf[['target']]], axis = 1)\n",
    "        ##If randomizing the order, should we use the dataframe 'finalDf'?\n",
    "        return dataTargetDf\n",
    "\n",
    "    def subset(self,dataTargetDf, subsetfrac:float):\n",
    "        \n",
    "        # Usage: If 20% of the data is to be randomly selected\n",
    "        # subsetDf = subset(dataTargetDf, 0.2)\n",
    "        \n",
    "        return dataTargetDf.sample(frac = subsetfrac)\n",
    "\n",
    "    def sample_selection(self,training_sample):\n",
    "        pass\n",
    "    \n",
    "    def _hinge_loss_svm(self,traindata, trainlabel,W,w):\n",
    "        m = traindata.shape[1]\n",
    "        # Equation for the regularizer.\n",
    "        # It is the lambda*(norm2 of W)**2\n",
    "        # Here \"lambda\" is a non negative constant\n",
    "        lambd = cp.Parameter(nonneg=True)\n",
    "\n",
    "        ## Ideally we will have to try using different values fro \"lambda\"\n",
    "        ## For the sake of testing the code, we have set it to 0.01\n",
    "        ## Do we need to have a lambda?\n",
    "        lambd = 0.01 \n",
    "        reg_loss = cp.norm(W,p=2)**2\n",
    "        \n",
    "        #hinge loss\n",
    "        hinge_loss = cp.sum(cp.pos(1-cp.multiply(trainlabel,traindata @ W - w)))\n",
    "        \n",
    "\n",
    "        \n",
    "        #Objective is to minimize reg_loss and hinge_loss\n",
    "        # objective_func = cp.Minimize(hinge_loss/m + lambd*reg_loss)\n",
    "        prob = cp.Problem(cp.Minimize(hinge_loss/m + lambd*reg_loss))\n",
    "        # Now framing the LP, along with the constraints\n",
    "        return prob\n",
    "\n",
    "    def _normal_loss_svm(self,traindata,trainlabel, W,w):\n",
    "        #Constraint\n",
    "        # For every feature vector traindata[i] and its corresponding label trainlabel[i]:\n",
    "        # W^T*traindata[i] + w >= 1\n",
    "        const = [trainlabel[i]*(traindata[i]@ W + w) >= 1 for i in range(traindata.shape[0])]\n",
    "        ##Check the dimensions in the above constraint equation\n",
    "        \n",
    "        #Objective is to minimize reg_loss and hinge_loss\n",
    "        # objective_func = cp.Minimize(hinge_loss/m + lambd*reg_loss)\n",
    "        objective_func = cp.Minimize(0.5*cp.norm(W,p=2)**2)\n",
    "        prob = cp.Problem(objective_func,constraints=const)\n",
    "        # Now framing the LP, along with the constraints\n",
    "        return prob\n",
    "\n",
    "    def train(self,traindata,trainlabel):\n",
    "        \n",
    "        #USAGE\n",
    "        # W, w = train(traindata, trainlabel)\n",
    "\n",
    "        # m: Number of feature vectors\n",
    "        # W and w: Weight vector and Bias value respectively\n",
    "        print(traindata.shape)\n",
    "        m = traindata.shape[1]\n",
    "        W = cp.Variable((m,1))\n",
    "        w = cp.Variable()\n",
    "\n",
    "        \n",
    "        prob = self._hinge_loss_svm(traindata,trainlabel,W,w)\n",
    "\n",
    "        prob.solve()\n",
    "        \n",
    "        # Solving the problem would give us the optimal values from W and w;\n",
    "        # which have to be returned, so that we can use them while testing\n",
    "\n",
    "        ## adding to class variable\n",
    "        self.w = W\n",
    "        self.b = w\n",
    "        \n",
    "\n",
    "    def f(self,test_input):\n",
    "        test_val = test_input.dot(self.w.value) -  self.b.value\n",
    "        if test_val < -1:\n",
    "            test_val= -1\n",
    "        elif test_val > 1:\n",
    "            test_val = 1\n",
    "        else:\n",
    "            test_val = 0 \n",
    "            #it should classify the points in the P2 region as well, code should be modified to always return either 1 or 0)\n",
    "        estimated_class = self.classes.get(test_val)\n",
    "        return estimated_class\n",
    "    \n",
    "    def assess_classifier_performance(self,performance):\n",
    "        performance = np.asarray(performance)\n",
    "        correct = (np.count_nonzero(performance)/len(performance))*100\n",
    "        return correct\n",
    "\n",
    "    def test(self,dataset_test):\n",
    "        testlabel,testdata= self.prepare_binary(dataset_test)\n",
    "        res = []\n",
    "        performance = []\n",
    "        for i in range(testdata.shape[0]):\n",
    "            result = self.f(testdata[i])\n",
    "            res.append(result)\n",
    "            \n",
    "            actual_class = self.classes.get(int(testlabel[i]))\n",
    "            \n",
    "            if result == actual_class:\n",
    "                performance.append(1)\n",
    "            else:\n",
    "                performance.append(0)\n",
    "                # we have return only the results as per the description \n",
    "        return res, performance\n",
    "    \n",
    "    def plot_classifier_performance_vs_number_of_samples(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01cb10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1369.2509985955885 659.5185289614332 709.7324696341552\n"
     ]
    }
   ],
   "source": [
    "#train1 = label1, train2 = label7, train3 = label 1 + 7 \n",
    "\n",
    "df = pd.read_csv(\"D:\\ip\\mnist_train.csv\") \n",
    "label1data = df.loc[df['label'] == 1] #all rows corresponding to label1\n",
    "label2data = df.loc[df['label'] == 7] #all rows corresponding to label7\n",
    "label3data = df.loc[df['label'].isin([1,7])]\n",
    "train1_count = len(label1data)\n",
    "train2_count = len(label2data)\n",
    "train3_count = len(label3data)\n",
    "train1_data = label1data.drop(columns = ['label']) #dropping the column1 consisting of labels\n",
    "train2_data = label2data.drop(columns = ['label'])\n",
    "train3_data = label3data.drop(columns = ['label'])\n",
    "\n",
    "c1 = train1_data.sum()/train1_count #centroid = sum of each component of all vectors/number\n",
    "c2 = train2_data.sum()/train2_count\n",
    "c3 = train3_data.sum()/train3_count\n",
    "\n",
    "dist12 = la.norm(c1-c2) #dist between centroids of 1 and 2\n",
    "dist13 = la.norm(c1-c3)\n",
    "dist23 = la.norm(c2-c3)\n",
    "\n",
    "print(dist12, dist13, dist23)\n",
    "\n",
    "#value of dist12, dist13, dist23 = (1369.2509985955885 659.5185289614332 709.7324696341552)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "09f9a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "(5000, 786)\n",
      "(2633, 786)\n",
      "(8, 787)\n"
     ]
    }
   ],
   "source": [
    "#np.array(train2_data.head(1))-np.array(train1_data.head(1))\n",
    "#la.norm(np.subtract(train2_data.to_numpy(),np.array(train1_data.head(1))),axis=1)\n",
    "\n",
    "dist = []\n",
    "\n",
    "def func_min_dist_p2_point(x):\n",
    "    #z = np.subtract(train2_data.to_numpy(),np.array(x))\n",
    "    #print(z.shape)\n",
    "    dist_min = np.min(la.norm(np.subtract(train2_data.to_numpy(),np.array(x)),axis=1))\n",
    "    #dist_min = np.min(la.norm(y, axis = 1))\n",
    "    return dist_min\n",
    "\n",
    "def dist_p1_centroid(x):\n",
    "    z = np.subtract(np.array(x[:-1]),np.array(c1))\n",
    "    return(la.norm(z))\n",
    "\n",
    "def dist_p2_centroid(x):\n",
    "    z = np.subtract(np.array(x[:-2]),np.array(c2))\n",
    "    return(la.norm(z))\n",
    "    \n",
    "\n",
    "x = train1_data[:5000]\n",
    "y = x.copy()\n",
    "y['Dist_other'] = y.apply(func_min_dist_p2_point,axis=1)\n",
    "y['Dist_own_centroid'] = y.apply(dist_p1_centroid,axis=1)\n",
    "#y['Dist_other_centroid'] = y.apply(dist_p2_centroid,axis=1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "selected_train1_logic1 = y.loc[y['Dist_other'] < y['Dist_own_centroid']]\n",
    "#selected_train1_logic2 = y.loc[y['Dist_other_centroid'] < y['Dist_own_centroid']]\n",
    "\n",
    "print(selected_train1_logic1.shape)\n",
    "print(selected_train1_logic2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cd03f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "def func_min_dist_point_to_label2(point):     \n",
    "    dist_min = np.min(la.norm(np.subtract(train2_data.to_numpy(),np.array(point)),axis=1))\n",
    "    return dist_min\n",
    "\n",
    "def func_min_dist_point_to_label1(point):     \n",
    "    dist_min = np.min(la.norm(np.subtract(train1_data.to_numpy(),np.array(point)),axis=1))\n",
    "    return dist_min\n",
    "\n",
    "def dist_to_centroid1(point):\n",
    "    z = np.subtract(np.array(point[:len(c1)]),np.array(c1))\n",
    "    return(la.norm(z))\n",
    "\n",
    "def dist_to_centroid2(point):\n",
    "    z = np.subtract(np.array(point[:len(c2)]),np.array(c2))\n",
    "    return(la.norm(z))\n",
    "\n",
    "\n",
    "def select_func(big_data_set,label):\n",
    "    if label == 1:\n",
    "        f = func_min_dist_point_to_label2\n",
    "        g = dist_to_centroid1\n",
    "    else:\n",
    "        f = func_min_dist_point_to_label1\n",
    "        g = dist_to_centroid2\n",
    "    \n",
    "    #big_data_set['Dist_other'] = big_data_set.apply(f,axis=1)\n",
    "    #big_data_set['Dist_own_centroid'] = big_data_set.apply(g,axis=1)\n",
    "    y = big_data_set.copy()\n",
    "    y['Dist_other'] = y.apply(f,axis=1)\n",
    "    y['Dist_own_centroid'] = y.apply(g,axis=1)\n",
    "    selected_train_logic1 = y.loc[y['Dist_other'] < y['Dist_own_centroid']]\n",
    "    return(selected_train_logic1)\n",
    "    \n",
    "\n",
    "x = select_func(train1_data[:200],1)\n",
    "y = select_func(train2_data[:200],2)\n",
    "\n",
    "print(type(x))\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e494ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6265,784) (786,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11232/1203009407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11232/2989494313.py\u001b[0m in \u001b[0;36mselect_func\u001b[1;34m(big_data_set, label)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#big_data_set['Dist_own_centroid'] = big_data_set.apply(g,axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbig_data_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dist_other'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dist_own_centroid'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mselected_train_logic1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dist_other'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dist_own_centroid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ip\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8739\u001b[0m         )\n\u001b[1;32m-> 8740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ip\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ip\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ip\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11232/2989494313.py\u001b[0m in \u001b[0;36mfunc_min_dist_point_to_label2\u001b[1;34m(point)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunc_min_dist_point_to_label2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdist_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdist_min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunc_min_dist_point_to_label1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6265,784) (786,) "
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "a = x.copy()\n",
    "b = y.copy()\n",
    "d = select_func(x,1)\n",
    "g = select_func(y,1)\n",
    "\n",
    "print(len(d))\n",
    "print(len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5386f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
